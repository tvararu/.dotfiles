services:
  ollama:
    container_name: ollama
    image: ollama/ollama:0.13.5
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ~/srv/ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  comfyui-api:
    container_name: comfyui-api
    image: ghcr.io/saladtechnologies/comfyui-api:comfy0.8.2-api1.17.0-torch2.8.0-cuda12.8-runtime
    restart: unless-stopped
    ports:
      - "8188:8188"
      - "8300:8300"
    extra_hosts:
      - "openclaw:100.91.68.60"
    volumes:
      - ~/srv/comfyui-api/cache:/root/.cache/comfyui-api
      - ~/srv/comfyui-api/output:/opt/ComfyUI/output
      - ~/srv/comfyui-api/manifest.yml:/manifest.yml:ro
      - ~/models:/opt/ComfyUI/models
    environment:
      - MANIFEST=/manifest.yml
      - PORT=8300
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  transmission:
    container_name: transmission
    image: linuxserver/transmission:4.0.5
    restart: unless-stopped
    ports:
      - "100.73.138.96:9091:9091"
      - "51413:51413"
      - "51413:51413/udp"
    volumes:
      - ~/srv/transmission/config:/config
      - ~/downloads:/downloads
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Asia/Bangkok

  cloudflared:
    container_name: cloudflared
    image: cloudflare/cloudflared:latest
    restart: unless-stopped
    command: tunnel run --token ${CLOUDFLARED_TOKEN}
    networks:
      - kamal

networks:
  kamal:
    external: true
