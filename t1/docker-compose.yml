services:
  ollama:
    container_name: ollama
    image: ollama/ollama:0.13.5
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ~/srv/ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  comfy:
    container_name: comfy
    image: mmartial/comfyui-nvidia-docker:ubuntu24_cuda13.0-20251219
    # restart: unless-stopped
    ports:
      - "8188:8188"
    volumes:
      - ~/srv/comfy:/comfy/mnt
      - ~/models:/comfy/mnt/ComfyUI/models
    environment:
      - WANTED_UID=1000
      - WANTED_GID=1000
      - USE_UV=true
      - FORCE_CHOWN=true
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu, compute, utility]

  comfy-api:
    container_name: comfy-api
    image: ghcr.io/saladtechnologies/comfyui-api:comfy0.5.1-api1.16.0-torch2.8.0-cuda12.8-runtime
    restart: unless-stopped
    network_mode: host
    volumes:
      - ~/srv/comfy-api/cache:/root/.cache/comfyui-api
      - ~/srv/comfy-api/output:/opt/ComfyUI/output
      - ~/srv/comfy-api/manifest.yml:/manifest.yml:ro
      - ~/models:/opt/ComfyUI/models
    environment:
      - MANIFEST=/manifest.yml
      - PORT=8300
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  transmission:
    container_name: transmission
    image: linuxserver/transmission:4.0.5
    restart: unless-stopped
    ports:
      - "100.73.138.96:9091:9091"
      - "51413:51413"
      - "51413:51413/udp"
    volumes:
      - ~/srv/transmission/config:/config
      - ~/downloads:/downloads
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Asia/Bangkok

  cloudflared:
    container_name: cloudflared
    image: cloudflare/cloudflared:latest
    restart: unless-stopped
    command: tunnel run --token ${CLOUDFLARED_TOKEN}
    networks:
      - kamal

networks:
  kamal:
    external: true
